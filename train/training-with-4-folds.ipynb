{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nfrom torchmetrics.functional import dice\n\nfrom transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\nfrom pytorch_lightning.loggers import CSVLogger\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/pretrained-models-pytorch\")\nsys.path.append(\"../input/efficientnet-pytorch\")\nsys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\nsys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\nimport segmentation_models_pytorch as smp","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-27T20:38:33.305797Z","iopub.execute_input":"2023-06-27T20:38:33.306174Z","iopub.status.idle":"2023-06-27T20:38:43.012028Z","shell.execute_reply.started":"2023-06-27T20:38:33.306143Z","shell.execute_reply":"2023-06-27T20:38:43.010672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    epochs = 20\n    train_bs = 48\n    valid_bs = 128\n    workers = 2\n    image_size = 384\n    num_warmup_steps = 350\n    num_training_steps = 3150\n    num_cycles = 1\n    loss_smooth = 1.0\n    lr = 0.0005\n    weight_decay = 0.0\n    train_folds = [0, 1, 2, 3]\n    \n    encoder_name = \"timm-resnest26d\"\n    data_path = \"/kaggle/input/my-data-for-contr\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_size=256, train=True):\n\n        self.df = df\n        self.trn = train\n        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        self.image_size = image_size\n        if image_size != 256:\n            self.resize_image = T.transforms.Resize(image_size)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        con_path = row.path\n        con = np.load(str(con_path))\n\n        img = con[..., :-1]\n        label = con[..., -1]\n\n        label = torch.tensor(label)\n\n        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n\n        if self.image_size != 256:\n            img = self.resize_image(img)\n\n        img = self.normalize_image(img)\n\n        return img.float(), label.float()\n\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T20:38:45.676540Z","iopub.execute_input":"2023-06-27T20:38:45.677227Z","iopub.status.idle":"2023-06-27T20:38:45.687943Z","shell.execute_reply.started":"2023-06-27T20:38:45.677196Z","shell.execute_reply":"2023-06-27T20:38:45.687068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LightningModule(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = smp.Unet(encoder_name=CFG.encoder_name,\n                              encoder_weights=\"imagenet\",\n                              in_channels=3,\n                              classes=1,\n                              activation=None,\n                             )\n        \n        self.loss_module = smp.losses.DiceLoss(mode=\"binary\", smooth=CFG.loss_smooth)\n        self.val_step_outputs = []\n        self.val_step_labels = []\n\n    def forward(self, batch):\n        imgs = batch\n        preds = self.model(imgs)\n        return preds\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), \n                          lr=CFG.lr, \n                          weight_decay=CFG.weight_decay\n                         )\n        \n        scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,\n                                                                       num_warmup_steps=CFG.num_warmup_steps,\n                                                                       num_training_steps=CFG.num_training_steps,\n                                                                       num_cycles=CFG.num_cycles\n                                                                      )\n        \n        lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n\n    def training_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        \n        if CFG.image_size != 256:\n            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n            \n        loss = self.loss_module(preds, labels)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=16)\n\n        for param_group in self.trainer.optimizers[0].param_groups:\n            lr = param_group[\"lr\"]\n        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        if CFG.image_size != 256:\n            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n        loss = self.loss_module(preds, labels)\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.val_step_outputs.append(preds)\n        self.val_step_labels.append(labels)\n\n    def on_validation_epoch_end(self):\n        all_preds = torch.cat(self.val_step_outputs)\n        all_labels = torch.cat(self.val_step_labels)\n        all_preds = torch.sigmoid(all_preds)\n        self.val_step_outputs.clear()\n        self.val_step_labels.clear()\n        val_dice = dice(all_preds, all_labels.long())\n        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True)\n        if self.trainer.global_rank == 0:\n            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-27T20:38:45.689610Z","iopub.execute_input":"2023-06-27T20:38:45.690236Z","iopub.status.idle":"2023-06-27T20:39:04.411915Z","shell.execute_reply.started":"2023-06-27T20:38:45.690203Z","shell.execute_reply":"2023-06-27T20:39:04.411020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stratified_kfold_loaders(metadata, num_splits=5, random_state=42):\n\n    skfold = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=random_state)\n\n    for n, (train_indices, valid_indices) in enumerate(skfold.split(metadata, metadata[\"contrail\"])):\n        metadata.loc[valid_indices, \"kfold\"] = int(n)\n    \n    return metadata","metadata":{"execution":{"iopub.status.busy":"2023-06-27T20:39:04.413250Z","iopub.execute_input":"2023-06-27T20:39:04.414405Z","iopub.status.idle":"2023-06-27T20:39:04.420507Z","shell.execute_reply.started":"2023-06-27T20:39:04.414369Z","shell.execute_reply":"2023-06-27T20:39:04.419286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(CFG.seed)\ngc.enable()\n\ncontrails = CFG.data_path + \"contrails/\"\ntrain_path = CFG.data_path + \"train_df.csv\"\nvalid_path = CFG.data_path + \"valid_df.csv\"\n\ntrain_df = pd.read_csv(train_path)\nvalid_df = pd.read_csv(valid_path)\n\ntrain_df['path'] = contrails + train_df['record_id'].astype(str) + '.npy'\nvalid_df['path'] = contrails + valid_df['record_id'].astype(str) + '.npy'\n\ndata = pd.concat([train_df, valid_df]).reset_index()\n\ndata = stratified_kfold_loaders(data, num_splits=4)\ndata['kfold'] = data['kfold'].astype(int)\n\nfor fold in CFG.train_folds:\n    print(f\"Fold {fold}\")\n    trn_df = data[data.kfold != fold].reset_index(drop=True)\n    vld_df = data[data.kfold == fold].reset_index(drop=True)\n\n    dataset_train = ContrailsDataset(trn_df, CFG.image_size, train=True)\n    dataset_validation = ContrailsDataset(vld_df, CFG.image_size, train=False)\n\n    data_loader_train = DataLoader(\n        dataset_train,\n        batch_size=CFG.train_bs,\n        shuffle=True,\n        num_workers=CFG.workers,\n    )\n    data_loader_validation = DataLoader(\n        dataset_validation,\n        batch_size=CFG.valid_bs,\n        shuffle=False,\n        num_workers=CFG.workers,\n    )\n\n    checkpoint_callback = ModelCheckpoint(\n        save_weights_only=True,\n        monitor=\"val_dice\",\n        dirpath=\"models\",\n        mode=\"max\",\n        filename=f\"model-f{fold}-{{val_dice:.4f}}\",\n        save_top_k=1,\n        verbose=1,\n    )\n\n    progress_bar_callback = TQDMProgressBar(refresh_rate=1)\n\n    early_stop_callback = EarlyStopping(monitor=\"val_loss\"\n                                        mode=\"min\"\n                                        patience=999\n                                        verbose=1\n                                       )\n\n    trainer = pl.Trainer(callbacks=[checkpoint_callback, early_stop_callback, progress_bar_callback],\n                         logger=CSVLogger(save_dir=f'logs_f{fold}/'),\n                         max_epochs=CFG.epochs,\n                         min_epochs=CFG.epochs,\n                         enable_progress_bar=True,\n                         precision=\"16-mixed\",\n                         devices=2,\n                        )\n\n    model = LightningModule()\n\n    trainer.fit(model, data_loader_train, data_loader_validation)\n\n    del (dataset_train,\n         dataset_validation,\n         data_loader_train,\n         data_loader_validation,\n         model,\n         trainer,\n         checkpoint_callback,\n         progress_bar_callback,\n         early_stop_callback,\n        )\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-27T20:39:04.422182Z","iopub.execute_input":"2023-06-27T20:39:04.422754Z"},"trusted":true},"execution_count":null,"outputs":[]}]}